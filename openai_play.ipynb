{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:39:10.511046Z",
     "start_time": "2025-03-20T13:39:10.407789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "ad8bd95a0033ac8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:44:02.985527Z",
     "start_time": "2025-03-20T13:44:02.964909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from farmbase_agent_toolkit.api import FarmbaseAPI\n",
    "\n",
    "api = FarmbaseAPI(secret_key=\"fdsfds\", context=None)\n",
    "\n",
    "get_tool_defs([api.create_farm, api.create_field, api.do_nothing])"
   ],
   "id": "9c7fcee7a4683746",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'create_farm',\n",
       "   'description': 'This tool creates a new farm in Farmbase',\n",
       "   'parameters': {'properties': {'name': {'type': 'string'},\n",
       "     'location': {'type': 'string'}},\n",
       "    'required': ['name', 'location'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'create_field',\n",
       "   'description': 'This tool creates a new field in Farmbase',\n",
       "   'parameters': {'$defs': {'LineString': {'description': 'LineString Model',\n",
       "      'properties': {'bbox': {'anyOf': [{'maxItems': 4,\n",
       "          'minItems': 4,\n",
       "          'prefixItems': [{'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'}],\n",
       "          'type': 'array'},\n",
       "         {'maxItems': 6,\n",
       "          'minItems': 6,\n",
       "          'prefixItems': [{'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'},\n",
       "           {'type': 'number'}],\n",
       "          'type': 'array'},\n",
       "         {'type': 'null'}],\n",
       "        'default': None,\n",
       "        'title': 'Bbox'},\n",
       "       'type': {'const': 'LineString', 'type': 'string'},\n",
       "       'coordinates': {'items': {'anyOf': [{'$ref': '#/$defs/Position2D'},\n",
       "          {'$ref': '#/$defs/Position3D'}]},\n",
       "        'minItems': 2,\n",
       "        'type': 'array'}},\n",
       "      'required': ['type', 'coordinates'],\n",
       "      'type': 'object'},\n",
       "     'Position2D': {'maxItems': 2,\n",
       "      'minItems': 2,\n",
       "      'prefixItems': [{'title': 'Longitude', 'type': 'number'},\n",
       "       {'title': 'Latitude', 'type': 'number'}],\n",
       "      'type': 'array'},\n",
       "     'Position3D': {'maxItems': 3,\n",
       "      'minItems': 3,\n",
       "      'prefixItems': [{'title': 'Longitude', 'type': 'number'},\n",
       "       {'title': 'Latitude', 'type': 'number'},\n",
       "       {'title': 'Altitude', 'type': 'number'}],\n",
       "      'type': 'array'}},\n",
       "    'properties': {'farm_id': {'format': 'uuid', 'type': 'string'},\n",
       "     'name': {'type': 'string'},\n",
       "     'boundary': {'$ref': '#/$defs/LineString'}},\n",
       "    'required': ['farm_id', 'name', 'boundary'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'do_nothing',\n",
       "   'description': '',\n",
       "   'parameters': {'properties': {}, 'type': 'object'}}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:19:45.433686Z",
     "start_time": "2025-03-21T10:19:45.430347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "def function_to_schema(func) -> dict:\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        signature = inspect.signature(func)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Failed to get signature for function {func.__name__}: {str(e)}\"\n",
    "        )\n",
    "\n",
    "    parameters = {}\n",
    "    for param in signature.parameters.values():\n",
    "        try:\n",
    "            param_type = type_map.get(param.annotation, \"string\")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(\n",
    "                f\"Unknown type annotation {param.annotation} for parameter {param.name}: {str(e)}\"\n",
    "            )\n",
    "        parameters[param.name] = {\"type\": param_type}\n",
    "\n",
    "    required = [\n",
    "        param.name\n",
    "        for param in signature.parameters.values()\n",
    "        if param.default == inspect._empty\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": func.__name__,\n",
    "        \"description\": (func.__doc__ or \"\").strip(),\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": parameters,\n",
    "            \"required\": required,\n",
    "        },\n",
    "    }"
   ],
   "id": "4cf5224cc5b72d07",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:51:45.833258Z",
     "start_time": "2025-03-21T10:51:44.924257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def some_function(\n",
    "        parameter1: int,  # Some description\n",
    "        parameter2: tuple[int, int] = (1, 2),  # p2 description\n",
    "):\n",
    "    \"\"\"\n",
    "    some_function docstring\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def sample_function(param_1, param_2, the_third_one: int, some_optional=\"John Doe\"):\n",
    "    \"\"\"\n",
    "    I can tell you about the black boot\n",
    "    \"\"\"\n",
    "    print(\"Hello, world\")\n",
    "\n",
    "\n",
    "# schema =  function_to_schema(sample_function)\n",
    "\n",
    "\n",
    "tools = [sample_function]\n",
    "tool_schemas = [function_to_schema(tool) for tool in tools]\n",
    "\n",
    "pprint(tool_schemas)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Look up the black boot.\"}],\n",
    "    # input=[{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}],\n",
    "    tools=tool_schemas\n",
    ")\n",
    "\n",
    "# print(response.output)\n",
    "message = response.choices[0].message\n",
    "\n",
    "message.tool_calls[0].function\n",
    "# strict=True : BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'some_function': In context=('properties', 'parameter2'), 'minItems' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].parameters', 'code': 'invalid_function_parameters'}}\n",
    "\n",
    "# strict=False : BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for function 'some_function': In context=('properties', 'parameter2'), array schema missing items.\", 'type': 'invalid_request_error', 'param': 'tools[0].parameters', 'code': 'invalid_function_parameters'}}"
   ],
   "id": "71d6db783053e680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'function': {'description': 'I can tell you about the black boot',\n",
      "               'name': 'sample_function',\n",
      "               'parameters': {'properties': {'param_1': {'type': 'string'},\n",
      "                                             'param_2': {'type': 'string'},\n",
      "                                             'some_optional': {'type': 'string'},\n",
      "                                             'the_third_one': {'type': 'integer'}},\n",
      "                              'required': ['param_1',\n",
      "                                           'param_2',\n",
      "                                           'the_third_one'],\n",
      "                              'type': 'object'}},\n",
      "  'type': 'function'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"param_1\":\"black\",\"param_2\":\"boot\",\"the_third_one\":1}', name='sample_function')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:13:18.854710Z",
     "start_time": "2025-03-21T12:13:09.056358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "tools = [{'description': 'gets the count of animals and size of the farm for a user',\n",
    "          'name': 'count_and_size',\n",
    "          'parameters': {'$defs': {'User': {'additionalProperties': False,\n",
    "                                            'properties': {'age': {'title': 'Age',\n",
    "                                                                   'type': 'integer'},\n",
    "                                                           'name': {'title': 'Name',\n",
    "                                                                    'type': 'string'}},\n",
    "                                            'required': ['name', 'age'],\n",
    "                                            'title': 'User',\n",
    "                                            'type': 'object'}},\n",
    "                         'additionalProperties': False,\n",
    "                         'properties': {'count': {'title': 'Count', 'type': 'integer'},\n",
    "                                        'size': {'anyOf': [{'type': 'number'},\n",
    "                                                           {'type': 'null'}],\n",
    "                                                 'title': 'Size'},\n",
    "                                        'user': {'$ref': '#/$defs/User'}},\n",
    "                         'required': ['count', 'size', 'user'],\n",
    "                         'title': 'simple_method_ParameterModel',\n",
    "                         'type': 'object'},\n",
    "          'strict': True,\n",
    "          'type': 'function'}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"Get the count of animals for user Peter?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response.output)"
   ],
   "id": "e2786a776ecfe6a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"count\":0,\"size\":null,\"user\":{\"age\":0,\"name\":\"Peter\"}}', call_id='call_ngGmjwCYTQ4kH5wy8pQ5C55P', name='count_and_size', type='function_call', id='fc_67dd57dcc5d081928deddad7162ca8ce0e2824a3081bcd99', status='completed')]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T13:26:48.979419Z",
     "start_time": "2025-03-21T13:26:45.968421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "tools = [{'description': 'This tool creates a new field in Farmbase\\n',\n",
    "  'name': 'create_field',\n",
    "  'parameters': {'$defs': {'Position2D': {'items': {'type': 'number'},\n",
    "                                          'type': 'array'}},\n",
    "                 'additionalProperties': False,\n",
    "                 'properties': {'boundary': {'description': 'the boundary of '\n",
    "                                                            'the field as a '\n",
    "                                                            'list of [long, '\n",
    "                                                            'lat] coordinates.',\n",
    "                                             'items': {'$ref': '#/$defs/Position2D'},\n",
    "                                             'title': 'Boundary',\n",
    "                                             'type': 'array'},\n",
    "                                'farm_id': {'description': 'The ID of the farm '\n",
    "                                                           'that the field '\n",
    "                                                           'belongs to.',\n",
    "                                            'title': 'Farm Id',\n",
    "                                            'type': 'string'},\n",
    "                                'name': {'description': 'the name of the '\n",
    "                                                        'field.',\n",
    "                                         'title': 'Name',\n",
    "                                         'type': 'string'}},\n",
    "                 'required': ['farm_id', 'name', 'boundary'],\n",
    "                 'title': 'create_field_ParameterModel',\n",
    "                 'type': 'object'},\n",
    "  'strict': True,\n",
    "  'type': 'function'}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"register my new field\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response.output)"
   ],
   "id": "89e4a9b32323ca3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseOutputMessage(id='msg_67dd6918c3988192b42399145a311c7700f46f408b974f40', content=[ResponseOutputText(annotations=[], text=\"Could you please provide the details for the new field? I'll need the following information:\\n\\n1. **Name** of the field.\\n2. **Boundary** coordinates (a list of `[longitude, latitude]` pairs defining the field's boundary).\\n3. **Farm ID** that the field belongs to.\", type='output_text')], role='assistant', status='completed', type='message')]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:26:00.758496Z",
     "start_time": "2025-03-22T12:25:59.309853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from collections import namedtuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/Users/markns/workspace/farmwise/.env\")\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: tuple[float, float]\n",
    "    temperature_range: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "LatLong = namedtuple('LatLong', \"lat long\")\n",
    "\n",
    "@function_tool\n",
    "def get_weather(lat_lon: tuple[float, float]) -> Weather:\n",
    "    print(\"[debug] get_weather called\")\n",
    "    return Weather(city=lat_long, temperature_range=\"14-20C\", conditions=\"Sunny with wind.\")\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Hello world\",\n",
    "    instructions=\"You are a helpful agent.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "    print(result.final_output)\n",
    "    # The weather in Tokyo is sunny.\n",
    "\n",
    "\n",
    "await main()"
   ],
   "id": "6c1ed6cc8e60364c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 400 - {'error': {'message': \"Invalid schema for function 'get_weather': In context=('properties', 'lat_lon'), 'minItems' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].parameters', 'code': 'invalid_function_parameters'}}. (request_id: req_ae8166f28d94d39f86ae7cc7dc686d96)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for function 'get_weather': In context=('properties', 'lat_lon'), 'minItems' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].parameters', 'code': 'invalid_function_parameters'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mBadRequestError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     35\u001B[39m     \u001B[38;5;28mprint\u001B[39m(result.final_output)\n\u001B[32m     36\u001B[39m     \u001B[38;5;66;03m# The weather in Tokyo is sunny.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m main()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmain\u001B[39m():\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     result = \u001B[38;5;28;01mawait\u001B[39;00m Runner.run(agent, \u001B[38;5;28minput\u001B[39m=\u001B[33m\"\u001B[39m\u001B[33mWhat\u001B[39m\u001B[33m'\u001B[39m\u001B[33ms the weather in Tokyo?\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     35\u001B[39m     \u001B[38;5;28mprint\u001B[39m(result.final_output)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/agents/run.py:210\u001B[39m, in \u001B[36mRunner.run\u001B[39m\u001B[34m(cls, starting_agent, input, context, max_turns, hooks, run_config)\u001B[39m\n\u001B[32m    205\u001B[39m logger.debug(\n\u001B[32m    206\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mRunning agent \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_agent.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (turn \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_turn\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    207\u001B[39m )\n\u001B[32m    209\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m current_turn == \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m210\u001B[39m     input_guardrail_results, turn_result = \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(\n\u001B[32m    211\u001B[39m         \u001B[38;5;28mcls\u001B[39m._run_input_guardrails(\n\u001B[32m    212\u001B[39m             starting_agent,\n\u001B[32m    213\u001B[39m             starting_agent.input_guardrails\n\u001B[32m    214\u001B[39m             + (run_config.input_guardrails \u001B[38;5;129;01mor\u001B[39;00m []),\n\u001B[32m    215\u001B[39m             copy.deepcopy(\u001B[38;5;28minput\u001B[39m),\n\u001B[32m    216\u001B[39m             context_wrapper,\n\u001B[32m    217\u001B[39m         ),\n\u001B[32m    218\u001B[39m         \u001B[38;5;28mcls\u001B[39m._run_single_turn(\n\u001B[32m    219\u001B[39m             agent=current_agent,\n\u001B[32m    220\u001B[39m             original_input=original_input,\n\u001B[32m    221\u001B[39m             generated_items=generated_items,\n\u001B[32m    222\u001B[39m             hooks=hooks,\n\u001B[32m    223\u001B[39m             context_wrapper=context_wrapper,\n\u001B[32m    224\u001B[39m             run_config=run_config,\n\u001B[32m    225\u001B[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001B[32m    226\u001B[39m         ),\n\u001B[32m    227\u001B[39m     )\n\u001B[32m    228\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    229\u001B[39m     turn_result = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._run_single_turn(\n\u001B[32m    230\u001B[39m         agent=current_agent,\n\u001B[32m    231\u001B[39m         original_input=original_input,\n\u001B[32m   (...)\u001B[39m\u001B[32m    236\u001B[39m         should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001B[32m    237\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/agents/run.py:719\u001B[39m, in \u001B[36mRunner._run_single_turn\u001B[39m\u001B[34m(cls, agent, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks)\u001B[39m\n\u001B[32m    716\u001B[39m \u001B[38;5;28minput\u001B[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001B[32m    717\u001B[39m \u001B[38;5;28minput\u001B[39m.extend([generated_item.to_input_item() \u001B[38;5;28;01mfor\u001B[39;00m generated_item \u001B[38;5;129;01min\u001B[39;00m generated_items])\n\u001B[32m--> \u001B[39m\u001B[32m719\u001B[39m new_response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._get_new_response(\n\u001B[32m    720\u001B[39m     agent,\n\u001B[32m    721\u001B[39m     system_prompt,\n\u001B[32m    722\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m    723\u001B[39m     output_schema,\n\u001B[32m    724\u001B[39m     handoffs,\n\u001B[32m    725\u001B[39m     context_wrapper,\n\u001B[32m    726\u001B[39m     run_config,\n\u001B[32m    727\u001B[39m )\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._get_single_step_result_from_response(\n\u001B[32m    730\u001B[39m     agent=agent,\n\u001B[32m    731\u001B[39m     original_input=original_input,\n\u001B[32m   (...)\u001B[39m\u001B[32m    738\u001B[39m     run_config=run_config,\n\u001B[32m    739\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/agents/run.py:862\u001B[39m, in \u001B[36mRunner._get_new_response\u001B[39m\u001B[34m(cls, agent, system_prompt, input, output_schema, handoffs, context_wrapper, run_config)\u001B[39m\n\u001B[32m    860\u001B[39m model = \u001B[38;5;28mcls\u001B[39m._get_model(agent, run_config)\n\u001B[32m    861\u001B[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001B[32m--> \u001B[39m\u001B[32m862\u001B[39m new_response = \u001B[38;5;28;01mawait\u001B[39;00m model.get_response(\n\u001B[32m    863\u001B[39m     system_instructions=system_prompt,\n\u001B[32m    864\u001B[39m     \u001B[38;5;28minput\u001B[39m=\u001B[38;5;28minput\u001B[39m,\n\u001B[32m    865\u001B[39m     model_settings=model_settings,\n\u001B[32m    866\u001B[39m     tools=agent.tools,\n\u001B[32m    867\u001B[39m     output_schema=output_schema,\n\u001B[32m    868\u001B[39m     handoffs=handoffs,\n\u001B[32m    869\u001B[39m     tracing=get_model_tracing_impl(\n\u001B[32m    870\u001B[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001B[32m    871\u001B[39m     ),\n\u001B[32m    872\u001B[39m )\n\u001B[32m    874\u001B[39m context_wrapper.usage.add(new_response.usage)\n\u001B[32m    876\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m new_response\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/agents/models/openai_responses.py:75\u001B[39m, in \u001B[36mOpenAIResponsesModel.get_response\u001B[39m\u001B[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m response_span(disabled=tracing.is_disabled()) \u001B[38;5;28;01mas\u001B[39;00m span_response:\n\u001B[32m     74\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m         response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fetch_response(\n\u001B[32m     76\u001B[39m             system_instructions,\n\u001B[32m     77\u001B[39m             \u001B[38;5;28minput\u001B[39m,\n\u001B[32m     78\u001B[39m             model_settings,\n\u001B[32m     79\u001B[39m             tools,\n\u001B[32m     80\u001B[39m             output_schema,\n\u001B[32m     81\u001B[39m             handoffs,\n\u001B[32m     82\u001B[39m             stream=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     83\u001B[39m         )\n\u001B[32m     85\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001B[32m     86\u001B[39m             logger.debug(\u001B[33m\"\u001B[39m\u001B[33mLLM responsed\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/agents/models/openai_responses.py:230\u001B[39m, in \u001B[36mOpenAIResponsesModel._fetch_response\u001B[39m\u001B[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, stream)\u001B[39m\n\u001B[32m    220\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    221\u001B[39m     logger.debug(\n\u001B[32m    222\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCalling LLM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.model\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with input:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    223\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjson.dumps(list_input,\u001B[38;5;250m \u001B[39mindent=\u001B[32m2\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mResponse format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse_format\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    228\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m230\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.responses.create(\n\u001B[32m    231\u001B[39m     instructions=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(system_instructions),\n\u001B[32m    232\u001B[39m     model=\u001B[38;5;28mself\u001B[39m.model,\n\u001B[32m    233\u001B[39m     \u001B[38;5;28minput\u001B[39m=list_input,\n\u001B[32m    234\u001B[39m     include=converted_tools.includes,\n\u001B[32m    235\u001B[39m     tools=converted_tools.tools,\n\u001B[32m    236\u001B[39m     temperature=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.temperature),\n\u001B[32m    237\u001B[39m     top_p=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.top_p),\n\u001B[32m    238\u001B[39m     truncation=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.truncation),\n\u001B[32m    239\u001B[39m     max_output_tokens=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001B[32m    240\u001B[39m     tool_choice=tool_choice,\n\u001B[32m    241\u001B[39m     parallel_tool_calls=parallel_tool_calls,\n\u001B[32m    242\u001B[39m     stream=stream,\n\u001B[32m    243\u001B[39m     extra_headers=_HEADERS,\n\u001B[32m    244\u001B[39m     text=response_format,\n\u001B[32m    245\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/openai/resources/responses/responses.py:1415\u001B[39m, in \u001B[36mAsyncResponses.create\u001B[39m\u001B[34m(self, input, model, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1386\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1387\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1388\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1413\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m   1414\u001B[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001B[32m-> \u001B[39m\u001B[32m1415\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m   1416\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/responses\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1417\u001B[39m         body=\u001B[38;5;28;01mawait\u001B[39;00m async_maybe_transform(\n\u001B[32m   1418\u001B[39m             {\n\u001B[32m   1419\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   1420\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m   1421\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minclude\u001B[39m\u001B[33m\"\u001B[39m: include,\n\u001B[32m   1422\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minstructions\u001B[39m\u001B[33m\"\u001B[39m: instructions,\n\u001B[32m   1423\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_output_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_output_tokens,\n\u001B[32m   1424\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m   1425\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mparallel_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: parallel_tool_calls,\n\u001B[32m   1426\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprevious_response_id\u001B[39m\u001B[33m\"\u001B[39m: previous_response_id,\n\u001B[32m   1427\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mreasoning\u001B[39m\u001B[33m\"\u001B[39m: reasoning,\n\u001B[32m   1428\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstore\u001B[39m\u001B[33m\"\u001B[39m: store,\n\u001B[32m   1429\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m   1430\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m   1431\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m: text,\n\u001B[32m   1432\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtool_choice\u001B[39m\u001B[33m\"\u001B[39m: tool_choice,\n\u001B[32m   1433\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtools\u001B[39m\u001B[33m\"\u001B[39m: tools,\n\u001B[32m   1434\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m   1435\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtruncation\u001B[39m\u001B[33m\"\u001B[39m: truncation,\n\u001B[32m   1436\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m   1437\u001B[39m             },\n\u001B[32m   1438\u001B[39m             response_create_params.ResponseCreateParams,\n\u001B[32m   1439\u001B[39m         ),\n\u001B[32m   1440\u001B[39m         options=make_request_options(\n\u001B[32m   1441\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m   1442\u001B[39m         ),\n\u001B[32m   1443\u001B[39m         cast_to=Response,\n\u001B[32m   1444\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   1445\u001B[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001B[32m   1446\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/openai/_base_client.py:1767\u001B[39m, in \u001B[36mAsyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1753\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1754\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1755\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1762\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_AsyncStreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1763\u001B[39m ) -> ResponseT | _AsyncStreamT:\n\u001B[32m   1764\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1765\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=\u001B[38;5;28;01mawait\u001B[39;00m async_to_httpx_files(files), **options\n\u001B[32m   1766\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1767\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/openai/_base_client.py:1461\u001B[39m, in \u001B[36mAsyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001B[39m\n\u001B[32m   1458\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1459\u001B[39m     retries_taken = \u001B[32m0\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1461\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._request(\n\u001B[32m   1462\u001B[39m     cast_to=cast_to,\n\u001B[32m   1463\u001B[39m     options=options,\n\u001B[32m   1464\u001B[39m     stream=stream,\n\u001B[32m   1465\u001B[39m     stream_cls=stream_cls,\n\u001B[32m   1466\u001B[39m     retries_taken=retries_taken,\n\u001B[32m   1467\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/workspace/farmwise/.venv/lib/python3.13/site-packages/openai/_base_client.py:1562\u001B[39m, in \u001B[36mAsyncAPIClient._request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001B[39m\n\u001B[32m   1559\u001B[39m         \u001B[38;5;28;01mawait\u001B[39;00m err.response.aread()\n\u001B[32m   1561\u001B[39m     log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1562\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1564\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_response(\n\u001B[32m   1565\u001B[39m     cast_to=cast_to,\n\u001B[32m   1566\u001B[39m     options=options,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1570\u001B[39m     retries_taken=retries_taken,\n\u001B[32m   1571\u001B[39m )\n",
      "\u001B[31mBadRequestError\u001B[39m: Error code: 400 - {'error': {'message': \"Invalid schema for function 'get_weather': In context=('properties', 'lat_lon'), 'minItems' is not permitted.\", 'type': 'invalid_request_error', 'param': 'tools[0].parameters', 'code': 'invalid_function_parameters'}}"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
